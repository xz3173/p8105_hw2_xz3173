---
title: "p8105_hw2_xz3173"
author: "Xue Zhang"
date: "2023-09-27"
output: github_document
---






```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
```





# Problem 1 Solutions

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).



```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
```




```{r}
pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop"))|>
  left_join(x = _, y = month_df) |>
  select(year, month, everything(), -day, -starts_with("prez"))
```
 
We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.
 
```{r}
snp = 
  read_csv("data/snp.csv",
           col_types = cols(date = col_date(format = "%m%d%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |>
  left_join(x = _, y = month_df) |>
  select(year, month, close)
```
 
Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.




```{r}
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment"
  ) |>
  left_join(x = _, y = month_df) |>
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r}
data_538 =
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r range(pols$year)[1]` to `r range(pols$year)[2]`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r range(snp$year)[1]` to `r range(snp$year)[2]`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.










# Problem 2

Read and clean the Mr.Trash Wheel sheet.

```{r}
mr_trash_wheel_df = 
  read_excel("data/trash_wheel_collection.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |>
  janitor::clean_names(case = "snake") |>
   mutate(
    homes_powered = (weight_tons) * 500 / 30,
    trash_wheel = "mr")
```

Read and clean the Professor Trash Wheel sheet.

```{r}
professor_trash_wheel_df = 
  read_excel("data/trash_wheel_collection.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |>
  janitor::clean_names(case = "snake") |>
   mutate(
    homes_powered = (weight_tons) * 500 / 30,
    year = as.character(year),
    trash_wheel = "professor")
```

Read and clean the Gwynnda Trash Wheel sheet.

```{r}
gwynnda_trash_wheel_df =
  read_excel("data/trash_wheel_collection.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>
  janitor::clean_names() |>
   mutate(
    homes_powered = (weight_tons) * 500 / 30,
    year = as.character(year),
    trash_wheel = "gwynnda")
```

Combine datasets. 

```{r}
trash_wheel_collection_df =
  bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df)

str(trash_wheel_collection_df)
```

The `mr_trash_wheel_df` data has `r nrow(mr_trash_wheel_df)` observations and `r ncol(mr_trash_wheel_df)` variables and tells us about the information on the dumpster number, date of collection, amount of total litter and litter type for a given year during `r range(pull(mr_trash_wheel_df, year))`. The total weight of trash collected by Mr. Trash Wheel is `r sum(pull(mr_trash_wheel_df, weight_tons))` tons. The total number of cigarette butts collected by Mr.Trash Wheel is `r sum(pull(mr_trash_wheel_df, cigarette_butts))`. The total homes powered is `r sum(pull(mr_trash_wheel_df, homes_powered))` kilowatts. The average homes powered is `r mean(pull(mr_trash_wheel_df, homes_powered))` kilowatts. 

The `professor_trash_wheel_df` data has `r nrow(professor_trash_wheel_df)` observations and `r ncol(professor_trash_wheel_df)` variables and tells us about the information on the dumpster number, date of collection, amount of total litter and litter type for a given year during `r range(pull(professor_trash_wheel_df, year))`. The total weight of trash collected by Professor Trash Wheel is `r sum(pull(professor_trash_wheel_df, weight_tons))` tons. The total number of cigarette butts collected by Professor Trash Wheel is `r sum(pull(professor_trash_wheel_df, cigarette_butts))`. The total homes powered is `r sum(pull(professor_trash_wheel_df, homes_powered))` kilowatts. The average homes powered is `r mean(pull(professor_trash_wheel_df, homes_powered))` kilowatts. 

The `gwynnda_trash_wheel_df` data has `r nrow(gwynnda_trash_wheel_df)` observations and `r ncol(gwynnda_trash_wheel_df)` variables and tells us about the information on the dumpster number, date of collection, amount of total litter and litter type for a given year during `r range(pull(gwynnda_trash_wheel_df, year))`. The total weight of trash collected by Gwynnda Trash Wheel is `r sum(pull(gwynnda_trash_wheel_df, weight_tons))` tons. The total number of cigarette butts collected by Gwynnda Trash Wheel is `r sum(pull(gwynnda_trash_wheel_df, cigarette_butts))`. The total homes powered is `r sum(pull(gwynnda_trash_wheel_df, homes_powered))` kilowatts. The average homes powered is `r mean(pull(gwynnda_trash_wheel_df, homes_powered))` kilowatts. The total number of cigarette butts collected by Gwynnda in July of 2021  is `r filter(gwynnda_trash_wheel_df, month == "July", year == 2021) |> pull(cigarette_butts) |> sum()`.



# Problem 3

Import, clean, and tidy the dataset of baseline demographics. 


```{r}
mci_baseline_df =
  
  # import dataset
  read_csv("data/mci_baseline.csv", skip = 1) |>
  
  # clean names
  janitor::clean_names() |>
  
  # ensure that sex and APOE4 variables are appropriate encoded
  mutate(
    sex =
      case_match(
        sex,
        1 ~ "Male",
        0 ~ "Female"),
    sex = as.character(sex),
    
    apoe4 =
      case_match(
        apoe4,
        1 ~ "carrier",
        0 ~ "non-carrier"),
    apoe4 = as.character(apoe4)) |>
  
  # remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline)
  filter(age_at_onset == "." | current_age < age_at_onset) |>
  
  mutate(
    age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset),
    age_at_onset = as.numeric(age_at_onset))

# participants were recruited
nrow(mci_baseline_df)
  
# participants developed MCI
sum(!is.na(pull(mci_baseline_df, age_at_onset))) 

# the average baseline age
mean(pull(mci_baseline_df, current_age))

# proportion of women in the study are APOE4 carriers
women = mci_baseline_df |>
  filter(sex == "Female") 

apoe4_women = women |>
  filter(apoe4 == "carrier")

proportion_apoe4_women = nrow(apoe4_women) / nrow(women)

proportion_apoe4_women
```



The `mci_baseline_df` data has `r nrow(mci_baseline_df)` observations and `r ncol(mci_baseline_df)` variables and tells us about the basic demographic information measured at the study baseline and the development of MCI and the age of onset during the follow-up period, as well as the APOE4 carrier. The `mci_baseline_df` dataset has removed the participants who do not meet the stated inclusion critieria. There are total of `r nrow(mci_baseline_df)` participants were recruited, and of these `r sum(!is.na(pull(mci_baseline_df, age_at_onset)))` participants develop MCI. The average baseline age is `r mean(pull(mci_baseline_df, current_age))` years old. The proportion of women in the study with APOE4 carriers are `r proportion_apoe4_women`. There are also some `NA` values in the `age_at_onset` variables, which indicate that the participant remains MCI free during the follow-up period.





Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values. 

```{r}
mci_amyloid_df = 
  
  # import dataset
  read_csv("data/mci_amyloid.csv", skip = 1) |>
  
  # clean names
  janitor::clean_names() |>
  
  # make a clean, and tidy dataset of longitudinally observed biomarker values
  pivot_longer(
    baseline: time_8,
    names_to = "time_in_years",
    names_prefix = "time_",
    values_to = "follow_up") |>
  rename(id = study_id)
```


The `mci_amyloid_df` data has `r nrow(mci_amyloid_df)` observations and `r ncol(mci_amyloid_df)` variables and tells us about the information since the study baseline to the visit where biomarker Amyloid ratio was measured during a range of 2, 4, 6, 8 years. The tidy dataset has a longitudinally observed biomarker values in one column. Notice that tthere are some `NA` values in the `follow_up` variable, which indicate that the value of these variable is missing at those locations. However, the original csv did not specify the reasons of missing values. It might indicate that the pariticpant remains amyloid free during the follow-up period, or just lose track during the follow-up period.



```{r}
# participants appear in only the baseline dataset
baseline = mci_baseline_df |>
  anti_join(mci_amyloid_df, by = "id")

nrow(baseline)
```


```{r}
# participants appear in only the amyloid dataset
amyloid = mci_amyloid_df |>
  anti_join(mci_baseline_df, by = "id")

nrow(amyloid)
```

There are `r nrow(baseline) ` participants appear in only the baseline dataset. There are `r nrow(amyloid)` participants appear in only the amyloid dataset. The number of unique participants in the `mci-amyloid_df` data is high, which may impact the comparability of analyses conducted on these two datasets. These two datasets are collected in an observational study to understand the trajectory of Alzheimer's disease biomarkers. The unique participants that missing from the other study might due to missing data, erros in data collection, or intentionally excluded from this study.

```{r}
# combine the demographic and biomarker datasets that only participants who appear in both datasets are retained
mci_df =
  inner_join(mci_baseline_df, mci_amyloid_df, by = "id") 
  
str(mci_df)

```



The `mci_df` dataset combines the `mci_baeline_df` and `mci_amyloid_df` datasets, has `r nrow(mci_df)` observations and `r ncol(mci_df)` variables, and tells us about the participants who attend both datasets. The columns of the `mci_df` dataset would combine both the demographic and biomarker information columns with the same variables names. The rows of the `mci_df` dataset is less than the number of rows in the two original datasets, because the participants only appear once.


```{r}
# export the result as a CSV
write_csv(mci_df, "data/mci_df.csv")
```
