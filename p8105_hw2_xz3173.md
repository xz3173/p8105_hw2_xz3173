p8105_hw2_xz3173
================
Xue Zhang
2023-09-27

# Problem 1 Solutions

We clean the 538 `pols` data, which provides information on the number
of national politicians who are democratic or republican at any given
time. There are some values for which `prez_gop` is `2` – these are
months in which Ford became President following Nixon’s resignation. In
the new `president` variable created as part of our data cleaning, we
code these as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
```

``` r
pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop"))|>
  left_join(x = _, y = month_df) |>
  select(year, month, everything(), -day, -starts_with("prez"))
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv("data/snp.csv",
           col_types = cols(date = col_date(format = "%m%d%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |>
  left_join(x = _, y = month_df) |>
  select(year, month, close)
```

    ## Warning: One or more parsing issues, call `problems()` on your data frame for details,
    ## e.g.:
    ##   dat <- vroom(...)
    ##   problems(dat)

    ## Joining with `by = join_by(month_num)`

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment"
  ) |>
  left_join(x = _, y = month_df) |>
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

Now we merge the three datasets!

``` r
data_538 =
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years NA to NA. The `unemployment` data has 816
observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

# Problem 2

Read and clean the Mr.Trash Wheel sheet.

``` r
mr_trash_wheel_df = 
  read_excel("data/trash_wheel_collection.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |>
  janitor::clean_names(case = "snake") |>
   mutate(
    homes_powered = (weight_tons) * 500 / 30,
    trash_wheel = "mr")
```

The `mr_trash_wheel_df` data has 584 observations and 15 variables and
tells us about the information on the dumpster number, date of
collection, amount of total litter and litter type for a given year
during 2014, 2023. The total weight of trash collected by Mr. Trash
Wheel is 1875.1 tons. The total number of cigarette butts collected by
Mr.Trash Wheel is 1.158222^{7}. The total homes powered is 3.1251667^{4}
kilowatts. The average homes powered is 53.5131279 kilowatts.

Read and clean the Professor Trash Wheel sheet.

``` r
professor_trash_wheel_df = 
  read_excel("data/trash_wheel_collection.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |>
  janitor::clean_names(case = "snake") |>
   mutate(
    homes_powered = (weight_tons) * 500 / 30,
    year = as.character(year),
    trash_wheel = "professor")
```

The `professor_trash_wheel_df` data has 106 observations and 14
variables and tells us about the information on the dumpster number,
date of collection, amount of total litter and litter type for a given
year during 2017, 2023. **The total weight of trash collected by
Professor Trash Wheel is 216.26 tons.** The total number of cigarette
butts collected by Professor Trash Wheel is NA. The total homes powered
is 3604.3333333 kilowatts. The average homes powered is 34.0031447
kilowatts.

Read and clean the Gwynnda Trash Wheel sheet.

``` r
gwynnda_trash_wheel_df =
  read_excel("data/trash_wheel_collection.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>
  janitor::clean_names() |>
   mutate(
    homes_powered = (weight_tons) * 500 / 30,
    year = as.character(year),
    trash_wheel = "gwynnda")
```

The `gwynnda_trash_wheel_df` data has 155 observations and 13 variables
and tells us about the information on the dumpster number, date of
collection, amount of total litter and litter type for a given year
during 2021, 2023. The total weight of trash collected by Gwynnda Trash
Wheel is 451.65 tons. The total number of cigarette butts collected by
Gwynnda Trash Wheel is 3.6701^{5}. The total homes powered is 7527.5
kilowatts. The average homes powered is 48.5645161 kilowatts. **The
total number of cigarette butts collected by Gwynnda in July of 2021 is
1.63^{4}.**

Combine datasets.

``` r
trash_wheel_collection_df =
  bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df)

str(trash_wheel_collection_df)
```

    ## tibble [845 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:845] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:845] "May" "May" "May" "May" ...
    ##  $ year              : chr [1:845] "2014" "2014" "2014" "2014" ...
    ##  $ date              : POSIXct[1:845], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:845] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:845] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:845] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:845] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:845] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:845] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ plastic_bags      : num [1:845] 584 496 1080 896 368 ...
    ##  $ wrappers          : num [1:845] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : num [1:845] 7.2 5.2 6 6 7.2 5.2 3.2 6.4 5.6 7.2 ...
    ##  $ homes_powered     : num [1:845] 71.8 45.7 57.5 51.7 67.7 ...
    ##  $ trash_wheel       : chr [1:845] "mr" "mr" "mr" "mr" ...

The `trash_wheel_collection df` data has 845 observations and 15
variables and tells us about the information on the all three datsets
including `mr_trash_wheel_df`, `professor_trash_wheel_df`,
`gwynnda_trash_wheel_df`. The total weight of trash collected by three
datasets is 2543.01 tons. The total number of cigarette butts collected
by three datasets is NA. The total homes powered is 4.23835^{4}
kilowatts. The average homes powered is 50.1579882 kilowatts.

# Problem 3

Import, clean, and tidy the dataset of baseline demographics.

``` r
mci_baseline_df =
  
  # import dataset
  read_csv("data/mci_baseline.csv", skip = 1) |>
  
  # clean names
  janitor::clean_names() |>
  
  # ensure that sex and APOE4 variables are appropriate encoded
  mutate(
    sex =
      case_match(
        sex,
        1 ~ "Male",
        0 ~ "Female"),
    sex = as.character(sex),
    
    apoe4 =
      case_match(
        apoe4,
        1 ~ "carrier",
        0 ~ "non-carrier"),
    apoe4 = as.character(apoe4)) |>
  
  # remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline)
  filter(age_at_onset == "." | current_age < age_at_onset) |>
  
  mutate(
    age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset),
    age_at_onset = as.numeric(age_at_onset))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# participants were recruited
nrow(mci_baseline_df)
```

    ## [1] 479

``` r
# participants developed MCI
sum(!is.na(pull(mci_baseline_df, age_at_onset))) 
```

    ## [1] 93

``` r
# the average baseline age
mean(pull(mci_baseline_df, current_age))
```

    ## [1] 65.0286

``` r
# proportion of women in the study are APOE4 carriers
women = mci_baseline_df |>
  filter(sex == "Female") 

apoe4_women = women |>
  filter(apoe4 == "carrier")

proportion_apoe4_women = nrow(apoe4_women) / nrow(women)

proportion_apoe4_women
```

    ## [1] 0.3

The `mci_baseline_df` data has 479 observations and 6 variables and
tells us about the basic demographic information measured at the study
baseline and the development of MCI and the age of onset during the
follow-up period, as well as the APOE4 carrier. The `mci_baseline_df`
dataset has removed the participants who do not meet the stated
inclusion criteria. **There are total of 479 participants were
recruited, and of these 93 participants develop MCI. The average
baseline age is 65.0286013 years old. The proportion of women in the
study with APOE4 carriers are 0.3.** There are also some `NA` values in
the `age_at_onset` variables, which indicate that the participant
remains MCI free during the follow-up period.

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values.

``` r
mci_amyloid_df = 
  
  # import dataset
  read_csv("data/mci_amyloid.csv", skip = 1) |>
  
  # clean names
  janitor::clean_names() |>
  
  
  # make a clean, and tidy dataset of longitudinally observed biomarker values
  pivot_longer(
    baseline: time_8,
    names_to = "time_in_years",
    names_prefix = "time_",
    values_to = "follow_up") |>
  rename(id = study_id)
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The `mci_amyloid_df` data has 2435 observations and 3 variables and
tells us about the information since the study baseline to the visit
where biomarker Amyloid ratio was measured during a range of 2, 4, 6, 8
years. The tidy dataset has a longitudinally observed biomarker values
in one column. Notice that there are some `NA` values in the `follow_up`
variable, which indicate that the value of these variable is missing at
those locations. However, the original csv did not specify the reasons
of missing values. It might indicate that the paticipant remains amyloid
free during the follow-up period, or just lose track during the
follow-up period.

``` r
# participants appear in only the baseline dataset
baseline = mci_baseline_df |>
  anti_join(mci_amyloid_df, by = "id")

nrow(baseline)
```

    ## [1] 8

``` r
# participants appear in only the amyloid dataset
amyloid = mci_amyloid_df |>
  anti_join(mci_baseline_df, by = "id")


unique_amyloid = unique(pull(amyloid,id))
num_unique_participants_in_amyloid = length(unique_amyloid)
print(num_unique_participants_in_amyloid)
```

    ## [1] 16

**There are 8 participants appear in only the baseline dataset. There
are 16 participants appear in only the amyloid dataset.** The number of
unique participants in the `mci-amyloid_df` data is high, which may
impact the comparability of analyses conducted on these two datasets.
These two datasets are collected in an observational study to understand
the trajectory of Alzheimer’s disease biomarkers. The unique
participants that missing from the other study might due to missing
data, errors in data collection, or intentionally excluded from this
study.

``` r
# combine the demographic and biomarker datasets that only participants who appear in both datasets are retained
mci_df =
  inner_join(mci_baseline_df, mci_amyloid_df, by = "id") 
  
str(mci_df)
```

    ## tibble [2,355 × 8] (S3: tbl_df/tbl/data.frame)
    ##  $ id           : num [1:2355] 1 1 1 1 1 2 2 2 2 2 ...
    ##  $ current_age  : num [1:2355] 63.1 63.1 63.1 63.1 63.1 65.6 65.6 65.6 65.6 65.6 ...
    ##  $ sex          : chr [1:2355] "Female" "Female" "Female" "Female" ...
    ##  $ education    : num [1:2355] 16 16 16 16 16 20 20 20 20 20 ...
    ##  $ apoe4        : chr [1:2355] "carrier" "carrier" "carrier" "carrier" ...
    ##  $ age_at_onset : num [1:2355] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ time_in_years: chr [1:2355] "baseline" "2" "4" "6" ...
    ##  $ follow_up    : chr [1:2355] "0.1105487" NA "0.109325197" "0.104756131" ...

``` r
unique_participants = unique(pull(mci_df,id))
num_unique_participants_in_both = length(unique_participants)
print(num_unique_participants_in_both)
```

    ## [1] 471

The `mci_df` dataset combines the `mci_baeline_df` and `mci_amyloid_df`
datasets, has 2355 observations and 8 variables, and tells us about
total of 471 participants who attend both datasets. The columns of the
`mci_df` dataset would combine both the demographic and biomarker
information columns with the same variables names. The rows of the
`mci_df` dataset is less than the number of rows in the two original
datasets, because the participants only appear once.

``` r
# export the result as a CSV
write_csv(mci_df, "data/mci_df.csv")
```
